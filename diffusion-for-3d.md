# Diffusion for 3D Generation

[arxiv 2022; Nvidia] Magic3D: High-Resolution Text-to-3D Content Creation \[[PDF](https://deepimagination.cc/Magic3D/), code\]

[arxiv 2022; google] DreamFusion: Text-to-3D using 2D Diffusion [[PDF](https://dreamfusion3d.github.io/), [code(unofficial)](https://github.com/ashawkey/stable-dreamfusion)]

[arxiv 2022.11; ]DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative Model \[[PDF](https://arxiv.org/pdf/2211.12824.pdf), code\]

[arxiv 2022.1; ]Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models [[PDF](https://arxiv.org/abs/2212.14704), [Page](https://bluestyle97.github.io/dream3d/)]

[arixv 2023.02] TEXTure: Text-Guided Texturing of 3D Shapes[[PDF](https://arxiv.org/abs/2302.01721), [Page](https://texturepaper.github.io/TEXTurePaper/)]

[arxiv 2023.02]Text-driven Visual Synthesis with Latent Diffusion Prior [[PDF](https://arxiv.org/abs/2302.08510), [Page](https://latent-diffusion-prior.github.io/)]

[arxiv 2023.02]3D-aware Conditional Image Synthesis [[PDF](https://arxiv.org/abs/2302.08509), [Page](https://www.cs.cmu.edu/~pix2pix3D/)]


## motion generation 
[arxiv 2024.10]CLoSD: Closing the Loop between Simulation and Diffusion for multi-task character control [[PDF](https://arxiv.org/abs/2410.03441),[Page](https://guytevet.github.io/CLoSD-page/)]


[arxiv 2024.10]   [[PDF](),[Page]()]


[arxiv 2024.10]   [[PDF](),[Page]()]
