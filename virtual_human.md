
## Face 
[arxiv 2024.12]   [[PDF](),[Page]()] ![Code](https://img.shields.io/github/stars/xxx?style=social&label=Star)



## Body 

[arxiv 2024.10] MotionAura: Generating High-Quality and Motion Consistent Videos using Discrete Diffusion  [[PDF](https://arxiv.org/abs/2410.07659)]

[arxiv 2024.10]  ControlMM: Controllable Masked Motion Generation [[PDF](http://arxiv.org/abs/2312.03596),[Page](https://exitudio.github.io/ControlMM-page/)]

[arxiv 2024.10] MotionBank: A Large-scale Video Motion Benchmark with Disentangled Rule-based Annotations  [[PDF](),[Page]()]

[arxiv 2024.10] Multi-modal Pose Diffuser: A Multimodal Generative Conditional Pose Prior  [[PDF](https://arxiv.org/abs/2410.14540)]

[arxiv 2024.10] LEAD: Latent Realignment for Human Motion Diffusion  [[PDF](https://arxiv.org/pdf/2410.14508)]

[arxiv 2024.10]  MotionCLR: Motion Generation and Training-free Editing via Understanding Attention Mechanisms [[PDF](https://arxiv.org/abs/2410.18977),[Page](https://lhchen.top/MotionCLR/)]

[arxiv 2024.11]  KMM: Key Frame Mask Mamba for Extended Motion Generation [[PDF](https://arxiv.org/abs/2411.06481),[Page](https://steve-zeyu-zhang.github.io/KMM/)]

[arxiv 2024.11] Rethinking Diffusion for Text-Driven Human Motion Generation  [[PDF](https://arxiv.org/abs/2411.16575)]

[arxiv 2024.11] SMGDiff: Soccer Motion Generation using diffusion probabilistic models  [[PDF](https://arxiv.org/abs/2411.16216)]

[arxiv 2024.11] DRiVE: Diffusion-based Rigging Empowers Generation of Versatile and Expressive Characters  [[PDF](https://arxiv.org/abs/2411.17423),[Page](https://driveavatar.github.io/)] ![Code](https://img.shields.io/github/stars/DRiVEAvatar/DRiVEAvatar.github.io?style=social&label=Star)

[arxiv 2024.11]  UniPose: A Unified Multimodal Framework for Human Pose Comprehension, Generation and Editing [[PDF](https://arxiv.org/abs/2411.16781)] 

[arxiv 2024.12] AToM: Aligning Text-to-Motion Model at Event-Level with GPT-4Vision Reward  [[PDF](https://arxiv.org/abs/2411.18654),[Page](https://atom-motion.github.io/)] ![Code](https://img.shields.io/github/stars/VincentHancoder/AToM?style=social&label=Star)

[arxiv 2024.12]  AdaVLN: Towards Visual Language Navigation in Continuous Indoor Environments with Moving Humans
 [[PDF](https://arxiv.org/abs/2411.18539),[Page](https://github.com/dillonloh/AdaVLN)] ![Code](https://img.shields.io/github/stars/dillonloh/AdaVLN?style=social&label=Star)

[arxiv 2024.12]  InfiniDreamer: Arbitrarily Long Human Motion Generation via Segment Score Distillation [[PDF](https://arxiv.org/abs/2411.18303)] 

[arxiv 2024.12] One Shot, One Talk: Whole-body Talking Avatar from a Single Image  [[PDF](https://arxiv.org/abs/2412.01106),[Page](https://ustc3dv.github.io/OneShotOneTalk/)] 

[arxiv 2024.12]  SoPo: Text-to-Motion Generation Using Semi-Online Preference Optimization [[PDF](https://sopo-motion.github.io/),[Page](https://sopo-motion.github.io/)] ![Code](https://img.shields.io/github/stars/xxx?style=social&label=Star)

[arxiv 2024.12]  Retrieving Semantics from the Deep: an RAG Solution for Gesture Synthesis [[PDF](https://arxiv.org/abs/2403.17936),[Page](https://vcai.mpi-inf.mpg.de/projects/RAG-Gesture/)] 

[arxiv 2024.12]  CoMA: Compositional Human Motion Generation with Multi-modal Agents [[PDF](https://arxiv.org/abs/2412.07320),[Page](https://gabrie-l.github.io/coma-page/)] ![Code](https://img.shields.io/github/stars/Siwensun/CoMA?style=social&label=Star)

[arxiv 2024.12]   [[PDF](),[Page]()] ![Code](https://img.shields.io/github/stars/xxx?style=social&label=Star)



## audio-to-gesture 
[arxiv 2024.10] Emphasizing Semantic Consistency of Salient Posture for Speech-Driven Gesture Generation  [[PDF](https://arxiv.org/abs/2410.13786)]

[arxiv 2024.12]   [[PDF](),[Page]()] ![Code](https://img.shields.io/github/stars/xxx?style=social&label=Star)




## Hands 


[arxiv 2024.10]Learning Interaction-aware 3D Gaussian Splatting for One-shot Hand Avatars [[PDF](https://arxiv.org/abs/2410.08840),[Page](https://github.com/XuanHuang0/GuassianHand)]

[arxiv 2024.11] UniHands: Unifying Various Wild-Collected Keypoints for Personalized Hand Reconstruction  [[PDF](https://arxiv.org/abs/2411.11845),[Page]()]

[arxiv 2024.12]  FoundHand: Large-Scale Domain-Specific Learning for Controllable Hand Image Generation [[PDF](https://arxiv.org/abs/2412.02690)]

[arxiv 2024.12]  HandOS: 3D Hand Reconstruction in One Stage [[PDF](https://arxiv.org/abs/2412.01537),[Page](https://idea-research.github.io/HandOSweb/)] 

[arxiv 2024.12] GigaHands: A Massive Annotated Dataset of Bimanual Hand Activities  [[PDF](https://arxiv.org/abs/2412.04244),[Page](https://ivl.cs.brown.edu/research/gigahands.html)] 


[arxiv 2024.12]   [[PDF](),[Page]()] ![Code](https://img.shields.io/github/stars/xxx?style=social&label=Star)



## Human Interaction 
[arxiv 2024.05]  Scaling Up Dynamic Human-Scene Interaction Modeling [[PDF](https://arxiv.org/abs/2403.08629),[Page](https://jnnan.github.io/trumans/)] ![Code](https://img.shields.io/github/stars/jnnan/trumans_utils?style=social&label=Star)

[arxiv 2024.06]  Introducing HOT3D: An Egocentric Dataset for 3D Hand and Object Tracking [[PDF](https://arxiv.org/pdf/2406.09598),[Page](https://facebookresearch.github.io/hot3d/)] ![Code](https://img.shields.io/github/stars/xxx?style=social&label=Star)

[arxiv 2024.10]  Sitcom-Crafter: A Plot-Driven Human Motion Generation System in 3D Scenes [[PDF](https://arxiv.org/abs/2410.10790),[Page](https://windvchen.github.io/Sitcom-Crafter/)]

[arxiv 2024.09] DreamHOI: Subject-Driven Generation of 3D Human-Object Interactions with Diffusion Priors[[PDF](https://arxiv.org/abs/2409.08278),[Page](https://dreamhoi.github.io/)]

[arxiv 2024.10] GraspDiffusion: Synthesizing Realistic Whole-body Hand-Object Interaction [[PDF](https://arxiv.org/abs/2410.13911),[Page]()]

[arxiv 2024.11] AnchorCrafter: Animate CyberAnchors Saling Your Products via Human-Object Interacting Video Generation  [[PDF](https://arxiv.org/abs/2411.17383),[Page](https://cangcz.github.io/Anchor-Crafter/)] ![Code](https://img.shields.io/github/stars/cangcz/AnchorCrafter?style=social&label=Star)

[arxiv 2024.12] HOT3D: Hand and Object Tracking in 3D from Egocentric Multi-View Videos  [[PDF](https://arxiv.org/abs/2411.19167),[Page](https://facebookresearch.github.io/hot3d/)] 

[arxiv 2024.12]  OOD-HOI: Text-Driven 3D Whole-Body Human-Object Interactions Generation Beyond Training Domains [[PDF](https://nickk0212.github.io/ood-hoi/#),[Page](https://nickk0212.github.io/ood-hoi/)] 

[arxiv 2024.12]  FIction: 4D Future Interaction Prediction from Video [[PDF](https://arxiv.org/abs/2408.00672),[Page](https://vision.cs.utexas.edu/projects/FIction/)] ![Code](https://img.shields.io/github/stars/thechargedneutron/FIction?style=social&label=Star)

[arxiv 2024.12]  TriDi: Trilateral Diffusion of 3D Humans, Objects and Interactions [[PDF](https://arxiv.org/abs/),[Page](https://virtualhumans.mpi-inf.mpg.de/tridi/)] ![Code](https://img.shields.io/github/stars/ptrvilya/tridi?style=social&label=Star)


[arxiv 2024.12]   [[PDF](),[Page]()] ![Code](https://img.shields.io/github/stars/xxx?style=social&label=Star)



## environment 
[arxiv 2024.10] DepthSplatï¼šConnecting Gaussian Splatting and Depth  [[PDF](https://arxiv.org/abs/2410.13862),[Page](https://haofeixu.github.io/depthsplat/)]

[arxiv 2024.10] Long-LRM: Long-sequence Large Reconstruction Model for Wide-coverage Gaussian Splats  [[PDF](https://arxiv.org/abs/2410.12781),[Page](https://arthurhero.github.io/projects/llrm/)]

[arxiv 2024.12]   [[PDF](),[Page]()] ![Code](https://img.shields.io/github/stars/xxx?style=social&label=Star)



## Capture 

[arxiv 2024.11] FreeCap: Hybrid Calibration-Free Motion Capture in Open Environments  [[PDF](https://arxiv.org/abs/2411.04469)]


[arxiv 2024.12]   [[PDF](),[Page]()] ![Code](https://img.shields.io/github/stars/xxx?style=social&label=Star)
